% LTeX: enabled=false
@inproceedings{46201,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
  title     = {Attention is all you need},
  year      = {2017},
  isbn      = {9781510860964},
  publisher = {Curran Associates Inc.},
  address   = {Red Hook, NY, USA},
  abstract  = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {6000–6010},
  numpages  = {11},
  location  = {Long Beach, California, USA},
  series    = {NIPS'17}
}

@misc{he2015deep,
  title         = {Deep Residual Learning for Image Recognition},
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year          = {2015},
  eprint        = {1512.03385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{Krizhevsky,
  author     = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title      = {ImageNet classification with deep convolutional neural networks},
  year       = {2017},
  issue_date = {June 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {60},
  number     = {6},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/3065386},
  doi        = {10.1145/3065386},
  abstract   = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  journal    = {Commun. ACM},
  month      = {may},
  pages      = {84–90},
  numpages   = {7}
}